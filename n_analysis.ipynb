{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "# import geopandas as gpd\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: migration1, dtype: int64)\n",
      "Series([], Name: migration2, dtype: int64)\n",
      "Series([], Name: migration3, dtype: int64)\n",
      "Series([], Name: migration4, dtype: int64)\n",
      "Series([], Name: migration5, dtype: int64)\n",
      "Series([], Name: migration6, dtype: int64)\n",
      "Series([], Name: migration7, dtype: int64)\n",
      "Series([], Name: migration8, dtype: int64)\n",
      "Series([], Name: migration9, dtype: int64)\n",
      "Series([], Name: migration10, dtype: int64)\n",
      "Series([], Name: migration11, dtype: int64)\n",
      "Series([], Name: migration12, dtype: int64)\n",
      "Series([], Name: migration13, dtype: int64)\n",
      "Series([], Name: migration14, dtype: int64)\n",
      "Series([], Name: migration15, dtype: int64)\n",
      "Series([], Name: migration16, dtype: int64)\n",
      "Series([], Name: migration17, dtype: int64)\n",
      "Series([], Name: migration18, dtype: int64)\n",
      "Series([], Name: migration19, dtype: int64)\n",
      "Series([], Name: migration20, dtype: int64)\n",
      "Series([], Name: migration21, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# median migration\n",
    "df = pd.read_pickle('in_migv2')\n",
    "migration_col = 'migration' + str(0)\n",
    "in_df = pd.DataFrame(df[0], columns=[migration_col, 'ifips', 'jfips'], dtype= int)\n",
    "\n",
    "for year in range(1, len(df)):\n",
    "    migration_col = 'migration' + str(year)\n",
    "    temp_df = pd.DataFrame(df[year], columns= [migration_col, 'ifips', 'jfips'], dtype= int)\n",
    "    in_df = pd.merge(in_df, temp_df,  how='left', left_on=['ifips','jfips'], right_on = ['ifips','jfips'])\n",
    "\n",
    "in_df['median_mig'] = in_df[['migration0', 'migration1', 'migration2', 'migration3',\n",
    "       'migration4', 'migration5', 'migration6', 'migration7', 'migration8',\n",
    "       'migration9', 'migration10', 'migration11', 'migration12',\n",
    "       'migration13', 'migration14', 'migration15', 'migration16',\n",
    "       'migration17', 'migration18', 'migration19', 'migration20',\n",
    "       'migration21']].median(axis=1)\n",
    "\n",
    "median_df = in_df[['ifips', 'jfips', 'median_mig']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns to match your actual column names if necessary\n",
    "source_county_col = 'ifips'\n",
    "target_county_col = 'jfips'\n",
    "migration_col = 'median_mig'\n",
    "\n",
    "# Define a function to extract the state FIPS code from a county FIPS code\n",
    "def county_to_state_fips(county_fips):\n",
    "    return int(str(county_fips).zfill(5)[:2])\n",
    "\n",
    "# Create a new DataFrame with the state FIPS codes for each county FIPS code\n",
    "median_df['source state'] = median_df[source_county_col].apply(county_to_state_fips)\n",
    "median_df['target state'] = median_df[target_county_col].apply(county_to_state_fips)\n",
    "\n",
    "# Group by source and target state FIPS codes and sum the migration values\n",
    "state_migration = median_df.groupby(['source state', 'target state'])[migration_col].sum().reset_index()\n",
    "state_migration = state_migration[(state_migration['source state'] != state_migration['target state'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['state_source', 'state_target'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m state_migration \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(state_migration, disasters_df,  how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget state\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_source\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_target\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# remove the extra columns\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m state_migration \u001b[38;5;241m=\u001b[39m \u001b[43mstate_migration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_source\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_target\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Display the new DataFrame\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(state_migration\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/core/frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5261\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5263\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5264\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5397\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5401\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5405\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5406\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5407\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/site-packages/pandas/core/indexes/base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6934\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6935\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['state_source', 'state_target'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Rename the columns in the new DataFrame\n",
    "state_migration.columns = ['source state', 'target state', 'migration']\n",
    "\n",
    "# Mapping to names\n",
    "state_fips_to_code = {\n",
    "    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', 11: 'DC', 12: 'FL', 13: 'GA',\n",
    "    15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', 21: 'KY', 22: 'LA', 23: 'ME', 24: 'MD',\n",
    "    25: 'MA', 26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO', 30: 'MT', 31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ',\n",
    "    35: 'NM', 36: 'NY', 37: 'NC', 38: 'ND', 39: 'OH', 40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC',\n",
    "    46: 'SD', 47: 'TN', 48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI', 56: 'WY'\n",
    "}\n",
    "\n",
    "# Convert the state FIPS codes to state codes\n",
    "state_migration['source state'] = state_migration['source state'].map(state_fips_to_code)\n",
    "state_migration['target state'] = state_migration['target state'].map(state_fips_to_code)\n",
    "\n",
    "# remove all the ones that have 0 migration\n",
    "state_migration = state_migration[state_migration['migration'] != 0]\n",
    "\n",
    "# convert migration to flux (normalize wrt median populuation (2000 + 2001)/2) https://www.iowadatacenter.org/datatables/UnitedStates/usstpopest20002002.pdf\n",
    "state_code_to_population = {\n",
    "    'AL': (4468912 + 4451975)/2, 'AK': (633630+627697)/2, 'AZ': (5306966+5167142)/2, 'AR': (2694698+2678668)/2, 'CA': (34600463+34010375)/2, 'CO': (4430989 + 4326758)/2, 'CT': (3434602 + 3411956) / 2, 'DE': (796599 + 786512)/2, 'DC': (573822 + 571641)/2, 'FL': (16373330 + 16051395)/2, 'GA': (8405677 + 8234373)/2,\n",
    "    'HI': (1227024 + 1212670)/2, 'ID': (1320585 + 1299721)/2, 'IL': (12520227 + 12440846)/2, 'IN': (6126743 + 6091950)/2, 'IA': (2931967 + 2928742)/2, 'KS': (2702125 + 2692557)/2, 'KY': (4068816 + 4048832)/2, 'LA': (4470368 + 4469768)/2, 'ME': (1284470 + 1277284)/2, 'MD': (5386079 + 5312461) / 2, 'MA': (6401164 + 6361720)/2, 'MI': (10006266 + 9956115)/2, 'MN': (4984535 + 4934248)/2, 'MS': (2859733 + 2848829)/2, 'MO': (5637309 + 5605067)/2, 'MT': (905382 + 903416)/2, 'NE': (1720039 + 1713375)/2, 'NV': (2097722 + 2018828)/2, 'NH': (1259359 + 1240472)/2, 'NJ': (8511116 + 8433276)/2,\n",
    "    'NM': (1830935 + 1821767)/2, 'NY': (19084350 + 18999760)/2, 'NC': (8206105 + 8082261)/2, 'ND': (636550 + 641131)/2, 'OH': (11389785 + 11363568)/2, 'OK': (3469577 + 3454408)/2, 'OR': (3473441 + 3431137)/2, 'PA': (12303104 + 12286107)/2, 'RI': (1059659 + 1050698)/2, 'SC': (4062125 + 4023725)/2, 'SD': (758324 + 755783)/2, 'TN': (5749398 + 5703246)/2, 'TX': (21370983 + 20955248)/2, 'UT': (2278712 + 2243406)/2, 'VT': (612978 + 609952)/2, 'VA': (7196750 + 7105900)/2, 'WA': (5993390 + 5911803)/2, 'WV': (1800975 + 1807326)/2, 'WI': (5405947 + 5374367)/2, 'WY': (493754 + 494086)/2\n",
    "}\n",
    "\n",
    "state_migration['migration_flux'] = state_migration['migration'] / state_migration['source state'].map(state_code_to_population)\n",
    "state_migration['source population'] = state_migration['source state'].map(state_code_to_population)\n",
    "state_migration['target population'] = state_migration['target state'].map(state_code_to_population)\n",
    "\n",
    "cols = ['source state', 'target state']\n",
    "\n",
    "# Add the state distance data to state_migration\n",
    "distances_df = pd.read_csv('./state_distances.csv')\n",
    "distances_df.columns = ['source state', 'target state', 'distance']\n",
    "state_migration = pd.merge(state_migration, distances_df,  how='left', left_on=cols, right_on=cols)\n",
    "\n",
    "# Add the state disaster and program data to state_migration\n",
    "disasters_df = pd.read_pickle('./disasters_mean_median.pkl')\n",
    "\n",
    "# Merge disasters_df and state_migration on state so that it creates an extra column for disasters of each state\n",
    "state_migration = pd.merge(state_migration, disasters_df,  how='left', left_on='source state', right_on='state', suffixes=('_source', '_target'))\n",
    "state_migration = pd.merge(state_migration, disasters_df,  how='left', left_on='target state', right_on='state', suffixes=('_source', '_target'))\n",
    "\n",
    "Create an empty directed graph\n",
    "G_state = nx.DiGraph()\n",
    "\n",
    "# Iterate through the rows in the DataFrame and add edges to the graph\n",
    "for index, row in state_migration.iterrows():\n",
    "    source = row['source state']\n",
    "    target = row['target state']\n",
    "    weight = row['migration_flux']\n",
    "    G_state.add_edge(source, target, weight=weight)\n",
    "\n",
    "# Print the graph's nodes and edges\n",
    "# print(\"Nodes:\", G_state.nodes())\n",
    "# print(\"Edges:\", G_state.edges(data=True))\n",
    "with open(\"./median_graph.p\", 'wb') as f:\n",
    "    pickle.dump(G_state, f)\n",
    "\n",
    "with open(\"./state_mig_median.pkl\", 'wb') as f:\n",
    "    pickle.dump(state_migration, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hurricane Katrina happened in August 2005, so we should look at 2006 data\n",
    "\n",
    "# 2006 migration\n",
    "df = pd.read_pickle('in_migv2')\n",
    "migration_col = 'migration_' + str(2006)\n",
    "df_2006 = pd.DataFrame(df[16], columns=[migration_col, 'ifips', 'jfips'], dtype= int)\n",
    "\n",
    "# Rename the columns to match your actual column names if necessary\n",
    "source_county_col = 'ifips'\n",
    "target_county_col = 'jfips'\n",
    "migration_col = 'migration_2006'\n",
    "\n",
    "# Define a function to extract the state FIPS code from a county FIPS code\n",
    "def county_to_state_fips(county_fips):\n",
    "    return int(str(county_fips).zfill(5)[:2])\n",
    "\n",
    "# Create a new DataFrame with the state FIPS codes for each county FIPS code\n",
    "df_2006['source state'] = df_2006[source_county_col].apply(county_to_state_fips)\n",
    "df_2006['target state'] = df_2006[target_county_col].apply(county_to_state_fips)\n",
    "\n",
    "# Group by source and target state FIPS codes and sum the migration values\n",
    "state_migration_2006 = df_2006.groupby(['source state', 'target state'])[migration_col].sum().reset_index()\n",
    "state_migration_2006 = state_migration_2006[(state_migration_2006['source state'] != state_migration_2006['target state'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns in the new DataFrame\n",
    "state_migration_2006.columns = ['source state', 'target state', 'migration']\n",
    "\n",
    "# Mapping to names\n",
    "state_fips_to_code = {\n",
    "    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', 11: 'DC', 12: 'FL', 13: 'GA',\n",
    "    15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', 21: 'KY', 22: 'LA', 23: 'ME', 24: 'MD',\n",
    "    25: 'MA', 26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO', 30: 'MT', 31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ',\n",
    "    35: 'NM', 36: 'NY', 37: 'NC', 38: 'ND', 39: 'OH', 40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC',\n",
    "    46: 'SD', 47: 'TN', 48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI', 56: 'WY'\n",
    "}\n",
    "\n",
    "# Convert the state FIPS codes to state codes\n",
    "state_migration_2006['source state'] = state_migration_2006['source state'].map(state_fips_to_code)\n",
    "state_migration_2006['target state'] = state_migration_2006['target state'].map(state_fips_to_code)\n",
    "\n",
    "# remove all the ones that have 0 migration\n",
    "state_migration_2006 = state_migration_2006[state_migration_2006['migration'] != 0]\n",
    "\n",
    "# convert migration to flux (normalize wrt 2006 population) https://fred.stlouisfed.org/release/tables?rid=118&eid=259194&od=2006-01-01\n",
    "state_code_to_population = {\n",
    "    'AL': 4628981, 'AK': 675302, 'AZ': 6029141, 'AR': 2821761, 'CA': 36021202, 'CO': 4720423, 'CT': 3517460, 'DE': 859268, 'DC': 570681, 'FL': 18166990, 'GA': 9155813,\n",
    "    'HI': 1309731, 'ID': 1468669, 'IL': 12643955, 'IN': 6332669, 'IA': 2982644, 'KS': 2762931, 'KY': 4219239, 'LA': 4302665, 'ME': 1323619, 'MD': 5627367, 'MA': 6410084, 'MI': 10036081, 'MN': 5163555, 'MS': 2904878, 'MO': 5842704, 'MT': 952692, 'NE': 1772693, 'NV': 2522658, 'NH': 1308389, 'NJ': 8661679, 'NM': 1962137, 'NY': 19104631, 'NC': 8917270, 'ND': 649422, 'OH': 11481213, 'OK': 3594090, 'OR': 3670883, 'PA': 12510809, 'RI': 1063096, 'SC': 4357847, 'SD': 783033, 'TN': 6088766, 'TX': 23359580, 'UT': 2525507, 'VT': 622892, 'VA': 7673725, 'WA': 6370753, 'WV': 1827912, 'WI': 5577655, 'WY': 522667\n",
    "}\n",
    "\n",
    "state_migration_2006['migration_flux'] = state_migration_2006['migration'] / state_migration_2006['source state'].map(state_code_to_population)\n",
    "state_migration_2006['source population'] = state_migration_2006['source state'].map(state_code_to_population)\n",
    "state_migration_2006['target population'] = state_migration_2006['target state'].map(state_code_to_population)\n",
    "\n",
    "# Add the state distance data to state_migration\n",
    "distances_df = pd.read_csv('./state_distances.csv')\n",
    "distances_df.columns = ['source state', 'target state', 'distance']\n",
    "state_migration_2006 = pd.merge(state_migration_2006, distances_df,  how='left', left_on=cols, right_on=cols)\n",
    "\n",
    "# Add the state disaster and program data to state_migration\n",
    "disasters_df = pd.read_pickle('./disasters_2006.pkl')\n",
    "\n",
    "# Merge disasters_df and state_migration on state so that it creates an extra column for disasters of each state\n",
    "state_migration_2006 = pd.merge(state_migration_2006, disasters_df,  how='left', left_on='source state', right_on='state', suffixes=('_source', '_target')).fillna(0)\n",
    "state_migration_2006 = pd.merge(state_migration_2006, disasters_df,  how='left', left_on='target state', right_on='state', suffixes=('_source', '_target')).fillna(0)\n",
    "\n",
    "# Create an empty directed graph\n",
    "G_state = nx.DiGraph()\n",
    "\n",
    "# Iterate through the rows in the DataFrame and add edges to the graph\n",
    "for index, row in state_migration_2006.iterrows():\n",
    "    source = row['source state']\n",
    "    target = row['target state']\n",
    "    weight = row['migration_flux']\n",
    "    G_state.add_edge(source, target, weight=weight)\n",
    "\n",
    "# Print the graph's nodes and edges\n",
    "print(\"Nodes:\", G_state.nodes())\n",
    "print(\"Edges:\", G_state.edges(data=True))\n",
    "with open(\"/Users/zasghar.19/Desktop/eeps1720/NetworkAnalysis/graph_2006.p\", 'wb') as f:\n",
    "    pickle.dump(G_state, f)\n",
    "\n",
    "with open(\"./state_mig_2006.pkl\", 'wb') as f:\n",
    "    pickle.dump(state_migration_2006, f)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "version": "3.10.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "orig_nbformat": 2,
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}