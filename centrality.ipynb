{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe median\n",
    "with open(\"./median_graph.p\", 'rb') as f:  # notice the r instead of w\n",
    "    median_graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframe median\n",
    "with open(\"./graph_2006.p\", 'rb') as f:  # notice the r instead of w\n",
    "    graph_2006 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary relating state code to (longitude, latitude)\n",
    "\n",
    "flipped_dict = {\n",
    "    \"AL\": (-86.791130, 32.806671),\n",
    "    \"AK\": (-152.404419, 61.370716),\n",
    "    \"AZ\": (-111.431221, 33.729759),\n",
    "    \"AR\": (-92.373123, 34.969704),\n",
    "    \"CA\": (-119.681564, 36.116203),\n",
    "    \"CO\": (-105.311104, 39.059811),\n",
    "    \"CT\": (-72.755371, 41.597782),\n",
    "    \"DE\": (-75.507141, 39.318523),\n",
    "    \"FL\": (-81.686783, 27.766279),\n",
    "    \"GA\": (-83.643074, 33.040619),\n",
    "    \"HI\": (-157.498337, 21.094318),\n",
    "    \"ID\": (-114.478828, 44.240459),\n",
    "    \"IL\": (-88.986137, 40.349457),\n",
    "    \"IN\": (-86.258278, 39.849426),\n",
    "    \"IA\": (-93.210526, 42.011539),\n",
    "    \"KS\": (-96.726486, 38.526600),\n",
    "    \"KY\": (-84.670067, 37.668140),\n",
    "    \"LA\": (-91.867805, 31.169546),\n",
    "    \"ME\": (-69.381927, 44.693947),\n",
    "    \"MD\": (-76.802101, 39.063946),\n",
    "    \"MA\": (-71.530106, 42.230171),\n",
    "    \"MI\": (-84.536095, 43.326618),\n",
    "    \"MN\": (-93.900192, 45.694454),\n",
    "    \"MS\": (-89.678696, 32.741646),\n",
    "    \"MO\": (-92.288368, 38.456085),\n",
    "    \"MT\": (-110.454353, 46.921925),\n",
    "    \"NE\": (-98.268082, 41.125370),\n",
    "    \"NV\": (-117.055374, 38.313515),\n",
    "    \"NH\": (-71.563896, 43.452492),\n",
    "    \"NJ\": (-74.521011, 40.298904),\n",
    "    \"NM\": (-106.248482, 34.840515),\n",
    "    \"NY\": (-74.948051, 42.165726),\n",
    "    \"NC\": (-79.806419, 35.630066),\n",
    "    \"ND\": (-99.784012, 47.528912),\n",
    "    \"OH\": (-82.764915, 40.388783),\n",
    "    \"OK\": (-96.928917, 35.565342),\n",
    "    \"OR\": (-122.070938, 44.572021),\n",
    "    \"PA\": (-77.209755, 40.590752),\n",
    "    \"RI\": (-71.511780, 41.680893),\n",
    "    \"SC\": (-80.945007, 33.856892),\n",
    "    \"SD\": (-99.438828, 44.299782),\n",
    "    \"TN\": (-86.350493, 35.747845),\n",
    "    \"TX\": (-97.563461, 31.054487),\n",
    "    \"UT\": (-111.862434, 40.150032),\n",
    "    \"VT\": (-72.710686, 44.045876),\n",
    "    \"VA\": (-78.169968, 37.769337),\n",
    "    \"WA\": (-120.740135, 47.751076),\n",
    "    \"WV\": (-80.454903, 38.597626),\n",
    "    \"WI\": (-89.616508, 44.268544),\n",
    "    \"WY\":  (-107.302490, 42.755966),\n",
    "    \"DC\": (-77.007507, 38.900497)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the centralities of states, choose one of the centrality analyses\n",
    "\n",
    "centrality_types = ['degree', 'betweenness', 'hub', 'eigenvector', 'pagerank']\n",
    "\n",
    "def graph_centrality(centrality_type):\n",
    "\n",
    "    if centrality_type == centrality_types[0]:\n",
    "        # degree centrality (coefficient used for sizing)\n",
    "        node_sizes = [a * 2000 for a in list(nx.degree_centrality(median_graph).values())]\n",
    "        node_sizes_2006 = [a * 2000 for a in list(nx.degree_centrality(graph_2006).values())]\n",
    "    elif centrality_type == centrality_types[1]:\n",
    "        # betweenness centrality (coefficient for sizing)\n",
    "        node_sizes = [a * 20000 for a in list(nx.betweenness_centrality(median_graph, weight='weight').values())]\n",
    "        node_sizes_2006 = [a * 20000 for a in list(nx.betweenness_centrality(graph_2006, weight='weight').values())]\n",
    "    elif centrality_type == centrality_types[2]:\n",
    "        # hub centrality (coefficient for sizing)\n",
    "        node_sizes = [a * 20000 for a in list(nx.hits(median_graph)[0].values())]\n",
    "        node_sizes_2006 = [a * 20000 for a in list(nx.hits(graph_2006)[0].values())]\n",
    "    elif centrality_type == centrality_types[3]:\n",
    "        # eigenvector centrality (coefficient for sizing)\n",
    "        node_sizes = [a * 40000 for a in list(nx.eigenvector_centrality(median_graph, max_iter=5000, weight='weight').values())]\n",
    "        node_sizes_2006 = [a * 40000 for a in list(nx.eigenvector_centrality(graph_2006, max_iter=5000, weight='weight').values())]\n",
    "    elif centrality_type == centrality_types[4]:\n",
    "        # pagerank centrality (coefficient for sizing)\n",
    "        node_sizes = [a * 40000 for a in list(nx.pagerank(median_graph).values())]\n",
    "        node_sizes_2006 = [a * 40000 for a in list(nx.pagerank(graph_2006).values())]\n",
    "    else:\n",
    "        print('error')\n",
    "        return -1\n",
    "\n",
    "\n",
    "    plt.figure(3,figsize=(18,12)) \n",
    "    # you can change median_graph to graph_2006\n",
    "    nx.draw(median_graph, with_labels=True, pos=flipped_dict, node_size=node_sizes)\n",
    "    title = centrality_type + ' Centrality of Median Migration'\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.show()\n",
    "\n",
    "graph_centrality(centrality_types[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph centralities median vs. 2006 \n",
    "\n",
    "entrality_types = ['degree', 'betweenness', 'hub', 'eigenvector', 'pagerank']\n",
    "\n",
    "def graph_centralities_compare(centrality_type):\n",
    "\n",
    "    if centrality_type == centrality_types[0]:\n",
    "        # degree centrality\n",
    "        degree_median = nx.degree_centrality(median_graph)\n",
    "        x = list(degree_median.values())\n",
    "        y = list(nx.degree_centrality(graph_2006).values())\n",
    "        n = list(degree_median.keys())\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        ax.axline((0, 0), slope=1)\n",
    "        plt.xlim(min(x), max(x))\n",
    "        plt.ylim(min(y), max(y))\n",
    "        plt.title('Degree Centrality—State Migration', fontsize=15)\n",
    "        plt.xlabel('Median Degree Centrality', fontsize=15)\n",
    "        plt.ylabel('2006 Degree Centrality', fontsize=15)\n",
    "        ax.scatter(x, y)\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (x[i], y[i]), fontsize=12)\n",
    "    elif centrality_type == centrality_types[1]:\n",
    "        # betweenness centrality\n",
    "        degree_median = nx.betweenness_centrality(median_graph, weight='weight')\n",
    "        x = list(degree_median.values())\n",
    "        y = list(nx.betweenness_centrality(graph_2006, weight='weight').values())\n",
    "        n = list(degree_median.keys())\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        ax.axline((0, 0), slope=1)\n",
    "        # plt.xlim(min(x), max(x))\n",
    "        # plt.ylim(min(y), max(y))\n",
    "        plt.title('Betweenness Centrality—State Migration', fontsize=15)\n",
    "        plt.xlabel('Median Betweenness Centrality', fontsize=15)\n",
    "        plt.ylabel('2006 Betweenness Centrality', fontsize=15)\n",
    "        ax.scatter(x, y)\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (x[i], y[i]), fontsize=12)\n",
    "    elif centrality_type == centrality_types[2]:\n",
    "        # hub centrality\n",
    "        degree_median = nx.hits(median_graph)[0]\n",
    "        x = list(degree_median.values())\n",
    "        y = list(nx.hits(graph_2006)[0].values())\n",
    "        n = list(degree_median.keys())\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        ax.axline((0, 0), slope=1)\n",
    "        # plt.xlim(min(x), max(x))\n",
    "        # plt.ylim(min(y), max(y))\n",
    "        plt.title('Hub Centrality—State Migration', fontsize=15)\n",
    "        plt.xlabel('Median Hub Centrality', fontsize=15)\n",
    "        plt.ylabel('2006 Hub Centrality', fontsize=15)\n",
    "        ax.scatter(x, y)\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (x[i], y[i]), fontsize=12)\n",
    "    elif centrality_type == centrality_types[3]:\n",
    "        # eigenvector centrality\n",
    "        degree_median = nx.eigenvector_centrality(median_graph, max_iter=5000, weight='weight')\n",
    "        x = list(degree_median.values())\n",
    "        y = list(nx.eigenvector_centrality(graph_2006, max_iter=5000, weight='weight').values())\n",
    "        n = list(degree_median.keys())\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        ax.axline((0, 0), slope=1)\n",
    "        # plt.xlim(min(x), max(x))\n",
    "        # plt.ylim(min(y), max(y))\n",
    "        plt.title('Eigenvector Centrality—State Migration', fontsize=15)\n",
    "        plt.xlabel('Median Eigenvector Centrality', fontsize=15)\n",
    "        plt.ylabel('2006 Eigenvector Centrality', fontsize=15)\n",
    "        ax.scatter(x, y)\n",
    "\n",
    "        for i, txt in enumerate(n):\n",
    "            ax.annotate(txt, (x[i], y[i]), fontsize=12)\n",
    "    elif centrality_type == centrality_types[4]:\n",
    "        # pagerank centrality\n",
    "        \n",
    "    else:\n",
    "        print('error')\n",
    "        return -1"
   ]
  }
 ]
}