{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38664bit386pyenv49c8da40f75d4a52ab4a97a513a5f232",
   "display_name": "Python 3.8.6 64-bit ('3.8.6': pyenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw pickled data for disasters\n",
    "\n",
    "df = pd.read_pickle('/Users/zasghar.19/Desktop/eeps1720/NetworkAnalysis/disasters.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts county to state fips\n",
    "def county_to_state_fips(county_fips):\n",
    "    return int(str(county_fips).zfill(5)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to names\n",
    "state_fips_to_code = {\n",
    "    1: 'AL', 2: 'AK', 4: 'AZ', 5: 'AR', 6: 'CA', 8: 'CO', 9: 'CT', 10: 'DE', 11: 'DC', 12: 'FL', 13: 'GA',\n",
    "    15: 'HI', 16: 'ID', 17: 'IL', 18: 'IN', 19: 'IA', 20: 'KS', 21: 'KY', 22: 'LA', 23: 'ME', 24: 'MD',\n",
    "    25: 'MA', 26: 'MI', 27: 'MN', 28: 'MS', 29: 'MO', 30: 'MT', 31: 'NE', 32: 'NV', 33: 'NH', 34: 'NJ',\n",
    "    35: 'NM', 36: 'NY', 37: 'NC', 38: 'ND', 39: 'OH', 40: 'OK', 41: 'OR', 42: 'PA', 44: 'RI', 45: 'SC',\n",
    "    46: 'SD', 47: 'TN', 48: 'TX', 49: 'UT', 50: 'VT', 51: 'VA', 53: 'WA', 54: 'WV', 55: 'WI', 56: 'WY'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the mean and median disasters\n",
    "\n",
    "years = ['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010']\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    year_df = df[year]\n",
    "    year_df['state fips'] = year_df['fips'].apply(county_to_state_fips)\n",
    "    year_df['state'] = year_df['state fips'].map(state_fips_to_code)\n",
    "    year_df = year_df[year_df['state'].notna()]\n",
    "    cols = ['ihProgramDeclared', 'iaProgramDeclared', 'paProgramDeclared', 'hmProgramDeclared', 'disasters']\n",
    "    filtered_df = year_df[cols + ['state']]\n",
    "    year_cols = [col + year for col in cols]\n",
    "    filtered_df.columns = year_cols + ['state']\n",
    "    filtered_df = filtered_df[year_cols + ['state']]\n",
    "    filtered_df = filtered_df.groupby('state')[year_cols].sum()\n",
    "    if year == '1991':\n",
    "        total_df = filtered_df\n",
    "    else:\n",
    "        total_df = pd.merge(total_df, filtered_df, how='outer', left_on=['state'], right_on=['state']).fillna(0)\n",
    "\n",
    "disasters_cols = ['disasters' + year for year in years]\n",
    "ih_cols = ['ihProgramDeclared' + year for year in years]\n",
    "ia_cols = ['iaProgramDeclared' + year for year in years]\n",
    "pa_cols = ['paProgramDeclared' + year for year in years]\n",
    "hm_cols = ['hmProgramDeclared' + year for year in years]\n",
    "\n",
    "total_df['disasters_median'] = total_df[disasters_cols].median(axis=1)\n",
    "total_df['ihProgramDeclared_median'] = total_df[ih_cols].median(axis=1)\n",
    "total_df['iaProgramDeclared_median'] = total_df[ia_cols].median(axis=1)\n",
    "total_df['paProgramDeclared_median'] = total_df[pa_cols].median(axis=1)\n",
    "total_df['hmProgramDeclared_median']  = total_df[hm_cols].median(axis=1)\n",
    "\n",
    "total_df['disasters_mean'] = total_df[disasters_cols].mean(axis=1)\n",
    "total_df['ihProgramDeclared_mean'] = total_df[ih_cols].mean(axis=1)\n",
    "total_df['iaProgramDeclared_mean'] = total_df[ia_cols].mean(axis=1)\n",
    "total_df['paProgramDeclared_mean'] = total_df[pa_cols].mean(axis=1)\n",
    "total_df['hmProgramDeclared_mean']  = total_df[hm_cols].mean(axis=1)\n",
    "\n",
    "median_cols = ['disasters_median', 'ihProgramDeclared_median', 'iaProgramDeclared_median', 'paProgramDeclared_median', 'hmProgramDeclared_median']\n",
    "mean_cols = ['disasters_mean', 'ihProgramDeclared_mean', 'iaProgramDeclared_mean', 'paProgramDeclared_mean', 'hmProgramDeclared_mean']\n",
    "mean_median_df = total_df[median_cols + mean_cols]\n",
    "\n",
    "with open(\"./disasters_mean_median.pkl\", 'wb') as f:\n",
    "    pickle.dump(mean_median_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./disasters_2006.pkl\", 'wb') as f:\n",
    "    pickle.dump(filtered_df, f)"
   ]
  }
 ]
}